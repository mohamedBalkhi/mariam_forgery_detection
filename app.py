# app.py
"""
Streamlit web application for digital image forgery detection.

This application allows users to upload an image (JPEG, PNG, TIFF, BMP)
and uses a pre-trained dual-input (RGB and ELA) Convolutional Neural Network
(CNN) model to predict whether the image is authentic or tampered.
The model leverages dual ResNet50V2 backbones for feature extraction.
Error Level Analysis (ELA) is performed
on the uploaded image to provide an additional input stream to the model.

The application handles model downloading from Google Drive if not found
locally (with optional checksum verification), provides UI elements for image upload and
result display, and includes information about the technology used.
TensorFlow/Keras is required for model operations.
"""

import streamlit as st
import hashlib
import logging
from pathlib import Path
import warnings
from PIL import Image, ImageChops, ImageEnhance, UnidentifiedImageError
import numpy as np
from datetime import datetime
import io

# Suppress TensorFlow warnings for cleaner output
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.filterwarnings('ignore', category=DeprecationWarning)

try:
    import tensorflow as tf
    import keras
    TF_AVAILABLE = True
    # Suppress specific TensorFlow warnings
    tf.get_logger().setLevel('ERROR')
except ImportError:
    TF_AVAILABLE = False
    # Mock keras for type hinting if TF is not available
    class keras: # type: ignore
        class layers:
            Layer = object
        class Model:
            pass
        class saving:
            def register_keras_serializable(self):
                def decorator(cls):
                    return cls
                return decorator
        class models:
            @staticmethod
            def load_model(*args, **kwargs):
                return None


# --- Application Configuration ---

# Image processing parameters
IMG_WIDTH = 224
IMG_HEIGHT = 224
IMAGE_SIZE = (IMG_HEIGHT, IMG_WIDTH)  # For model input: (height, width)
IMAGE_SIZE_PIL = (IMG_WIDTH, IMG_HEIGHT) # For PIL.Image.resize: (width, height)
ELA_QUALITY = 90  # JPEG quality for ELA generation
ELA_SCALE_FACTOR = 15  # Brightness enhancement for ELA image
MAX_FILE_SIZE_MB = 25 # Max upload file size in MB
MAX_IMAGE_DIMENSION = 8000 # Max width or height for an uploaded image

# Model details
MODEL_DIR = Path('models')
MODEL_NAME = 'best_dual_model_robust_head.keras'
MODEL_PATH = MODEL_DIR / MODEL_NAME  # Local path to the Keras model
GDRIVE_FILE_ID = '1aiLqyEm1kdUbxmjBJfE755H88r5Lu8Hq'  # Google Drive ID for model download

# Checksum verification - set to None to bypass
BYPASS_CHECKSUM = True  # Set to True to bypass checksum verification
MODEL_CHECKSUM = "e0b9a9d98c8a6f62d7f2b8c49f9e1a1b0a0b1c2d3e4f5a6b7c8d9e0f1a2b3c4d" # Example Checksum

# --- Logging Configuration ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='app.log', # Logs to app.log file
    filemode='a'
)
logger = logging.getLogger(__name__)

# Set page configuration
st.set_page_config(
    page_title="ÙƒØ§Ø´Ù ØªØ²ÙˆÙŠØ± Ø§Ù„ØµÙˆØ±",
    page_icon="ğŸ“·",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for better styling and Right-to-Left (RTL) layout support.
st.markdown("""
<style>
    /* Main Content Area Wrapper - For RTL text and centered layout */
    .rtl-main-area {
        direction: rtl;
        text-align: right;
        max-width: 950px;
        margin: 0 auto;
        padding: 0 1rem;
    }

    /* Headers */
    .app-header {
        font-size: 2.8rem;
        font-weight: bold;
        color: #2c3e50;
        text-align: center;
        margin-top: 1rem;
        margin-bottom: 0.5rem;
    }
    .app-subheader {
        font-size: 1.3rem;
        color: #555;
        text-align: center;
        margin-bottom: 2.5rem;
    }
    .section-header {
        font-size: 1.8rem;
        color: #3498db;
        text-align: center;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 2px solid #ecf0f1;
        padding-bottom: 0.5rem;
    }

    /* File Uploader Area */
    .upload-box {
        background-color: #f8f9fa;
        padding: 2rem;
        border-radius: 10px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.05);
        margin-bottom: 2rem;
        text-align: center;
    }

    /* Verify Button - Updated for better compatibility */
    button[kind="primary"] { 
        min-width: 220px !important;
        font-size: 1.2rem !important;
        font-weight: bold !important;
        padding: 0.75rem 2rem !important;
        border-radius: 8px !important;
        background-color: #3498db !important;
        color: white !important;
        border: none !important;
    }
    button[kind="primary"]:hover {
        background-color: #2980b9 !important;
    }

    /* Result Display */
    .result-box {
        padding: 1.5rem 2rem;
        border-radius: 10px;
        margin: 1rem auto;
        text-align: center;
        border-width: 2px;
        border-style: solid;
        max-width: 600px;
    }
    .result-box h3 {
        font-size: 1.6rem;
        font-weight: bold;
        margin-bottom: 0.5rem !important;
    }
    .authentic {
        background-color: #e6ffed;
        border-color: #5cb85c;
        color: #3c763d;
    }
    .authentic h3 {
        color: #3c763d !important;
    }
    .forged {
        background-color: #ffe6e6;
        border-color: #d9534f;
        color: #a94442;
    }
    .forged h3 {
        color: #a94442 !important;
    }

    /* Sidebar Styling - Updated for better compatibility */
    section[data-testid="stSidebar"] {
        direction: rtl; 
    }
    section[data-testid="stSidebar"] h2,
    section[data-testid="stSidebar"] h3,
    section[data-testid="stSidebar"] h4 {
        text-align: right !important;
        color: #0056b3; 
    }
    section[data-testid="stSidebar"] p,
    section[data-testid="stSidebar"] li {
        text-align: right !important;
        font-size: 0.95rem;
        color: #333;
        margin-bottom: 0.5rem;
        line-height: 1.6;
    }
    section[data-testid="stSidebar"] ul,
    section[data-testid="stSidebar"] ol {
        padding-right: 20px;
        padding-left: 0;
        margin-right: 10px; 
    }
    .sidebar-content {
        margin-bottom: 1.5rem;
    }
    section[data-testid="stSidebar"] img { 
        display: block;
        margin-left: auto;
        margin-right: auto;
        margin-bottom: 0.5rem; 
    }

    /* Metric styling */
    div[data-testid="metric-container"] {
        background-color: transparent !important;
        border: 1px solid #ddd;
        padding: 1rem;
        border-radius: 8px;
        text-align: center; 
        margin: 1rem auto;
        width: 280px; 
        direction: rtl; 
    }
    .stMetric label { 
        font-size: 1rem;
        color: #555;
        text-align: right !important; 
        display: block; 
        margin-bottom: 0.25rem;
    }
    .stMetric p { 
        font-size: 1.8rem !important;
        font-weight: bold;
        color: #333 !important;
        margin-bottom: 0 !important;
        text-align: center !important; 
    }

    /* Expander */
    .stExpander {
        border: 1px solid #eee;
        border-radius: 8px;
        margin: 1.5rem auto;
        max-width: 600px;
    }
    .stExpander header { 
        font-size: 1.1rem;
        text-align: right !important; 
    }
    .stExpander div[data-testid="stMarkdownContainer"] p,
    .stExpander div[data-testid="stMarkdownContainer"] ul,
    .stExpander div[data-testid="stMarkdownContainer"] li {
        direction: rtl;
        text-align: right !important;
    }
    .stExpander div[data-testid="stMarkdownContainer"] ul {
        padding-right: 20px; 
        padding-left: 0;
    }

    .centered-text {
        text-align: center;
        width: 100%;
    }
</style>
""", unsafe_allow_html=True)

# Check for gdown dependency
try:
    import gdown
except ImportError:
    logger.warning("gdown package not found. Please install it: pip install gdown")
    st.error("âŒ Ø­Ø²Ù…Ø© 'gdown' ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø²Ù…Ø© Ø¶Ø±ÙˆØ±ÙŠØ© Ù„ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
    st.info("Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªØ«Ø¨ÙŠØª Ø§Ù„Ø­Ø²Ù…Ø© ÙŠØ¯ÙˆÙŠØ§Ù‹ Ø¹Ù† Ø·Ø±ÙŠÙ‚ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØªØ§Ù„ÙŠ ÙÙŠ Ø§Ù„Ø·Ø±ÙÙŠØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ùƒ Ø«Ù… Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚:")
    st.code("pip install gdown")
    st.stop()


@keras.saving.register_keras_serializable()
class SRMLayer(keras.layers.Layer):
    """
    A Keras layer implementing Spatial Rich Model (SRM) filters.

    SRM filters are high-pass filters designed to extract subtle noise-like
    features from images, which can be indicative of manipulation. This layer
    applies a predefined set of SRM kernels as a 2D convolution.
    The kernels used are standard SRM filters (k1, k2, k3) for basic
    manipulation detection.

    The layer is registered as a Keras serializable object to allow
    model saving and loading.
    """
    def __init__(self, **kwargs):
        """
        Initializes the SRMLayer.

        Sets up the SRM filter kernels. These kernels are designed to
        capture high-frequency noise patterns.
        k1: A simple identity-like filter.
        k2: A simple negative identity-like filter.
        k3: A Laplacian-like filter often used in SRM.
        The kernels are stacked and reshaped to be compatible with 3-channel
        (RGB) images.
        """
        super().__init__(**kwargs)
        k1 = [[0,0,0],[0,1,0],[0,0,0]]
        k2 = [[0,0,0],[0,-1,0],[0,0,0]]
        k3 = [[-1,2,-1],[2,-4,2],[-1,2,-1]]
        
        ker = tf.constant([k1, k2, k3], tf.float32)      # Shape: (3, 3, 3)
        ker = tf.reshape(ker, (3,3,1,3))                 # Shape: (3, 3, 1, 3)
        ker = tf.repeat(ker, 3, axis=2)                  # Shape: (3, 3, 3, 3) (Input channels, Output feature maps)
        self.kernel = ker

    def call(self, x: tf.Tensor) -> tf.Tensor:
        """
        Applies the SRM convolution to the input tensor.

        Args:
            x: Input tensor, typically an image batch (B, H, W, C_in).

        Returns:
            Tensor with SRM features, with absolute values taken.
            Shape is (B, H, W, C_out), where C_out is determined by kernels.
        """
        x = tf.nn.conv2d(x, self.kernel, strides=1, padding='SAME')
        return tf.math.abs(x)

    def compute_output_shape(self, input_shape: tf.TensorShape) -> tf.TensorShape:
        """
        Computes the output shape of the layer.

        Args:
            input_shape: Shape of the input tensor.

        Returns:
            Shape of the output tensor.
        """
        return tf.TensorShape([
            input_shape[0],
            input_shape[1],
            input_shape[2],
            self.kernel.shape[-1] # Number of output filters
        ])


# --- Helper Functions ---
def calculate_sha256(filepath: Path) -> str:
    """Calculates the SHA256 checksum of a file."""
    sha256_hash = hashlib.sha256()
    with open(filepath, "rb") as f:
        for byte_block in iter(lambda: f.read(4096), b""):
            sha256_hash.update(byte_block)
    return sha256_hash.hexdigest()

def download_model_if_needed(model_path: Path, gdrive_file_id: str, expected_checksum: str = None) -> bool:
    """
    Downloads the model file from Google Drive if it doesn't exist locally
    and optionally verifies its checksum.

    Args:
        model_path: The local path (Path object) where the model should be saved.
        gdrive_file_id: The Google Drive file ID for the model.
        expected_checksum: The expected SHA256 checksum for the model file (optional).

    Returns:
        True if the model file exists locally and checksum matches (if verification enabled), 
        False otherwise.
    """
    models_dir = model_path.parent
    if not models_dir.exists():
        try:
            models_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            logger.error(f"Error creating models directory {models_dir}: {e}", exc_info=True)
            st.error("âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø°ÙˆÙ†Ø§Øª.")
            return False

    if not model_path.exists():
        url = f'https://drive.google.com/uc?id={gdrive_file_id}'
        status_text = st.empty()
        status_text.info("â¬ Ø¬Ø§Ø±ÙŠ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Google Drive... ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±.")
        
        try:
            with st.spinner("Downloading model... This may take a few moments."):
                 gdown.download(url, str(model_path), quiet=False) # quiet=False shows gdown's progress

            # Checksum verification (optional)
            if not BYPASS_CHECKSUM and expected_checksum:
                downloaded_checksum = calculate_sha256(model_path)
                if downloaded_checksum != expected_checksum:
                    logger.error(f"Model checksum mismatch for {model_path}. Expected {expected_checksum}, got {downloaded_checksum}")
                    st.error("âŒ Ø®Ø·Ø£: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙØ´Ù„. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ù…Ù„Ù ØªØ§Ù„ÙÙ‹Ø§ Ø£Ùˆ ØªÙ… Ø§Ù„ØªÙ„Ø§Ø¹Ø¨ Ø¨Ù‡.")
                    if model_path.exists():
                        model_path.unlink() # Delete corrupted/tampered file
                    status_text.empty()
                    return False
            
            status_text.success("âœ… ØªÙ… ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
            status_text.empty() # Clear message after a short while or next action
        except Exception as e:
            logger.error(f"Error downloading model from GDrive ID {gdrive_file_id} to {model_path}: {e}", exc_info=True)
            st.error("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ØªØµØ§Ù„Ùƒ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª.")
            if model_path.exists(): # Clean up partially downloaded file
                try:
                    model_path.unlink()
                except OSError as unlink_e:
                    logger.error(f"Error deleting partially downloaded model {model_path}: {unlink_e}", exc_info=True)
            status_text.empty()
            return False
    else: # Model already exists, optionally verify its checksum
        if not BYPASS_CHECKSUM and expected_checksum:
            try:
                existing_checksum = calculate_sha256(model_path)
                if existing_checksum != expected_checksum:
                    logger.warning(f"Existing model {model_path} has checksum mismatch. Expected {expected_checksum}, got {existing_checksum}. Re-downloading.")
                    if model_path.exists():
                        model_path.unlink()
                    return download_model_if_needed(model_path, gdrive_file_id, expected_checksum) # Recurse to download
            except Exception as e:
                logger.error(f"Error calculating checksum for existing model {model_path}: {e}", exc_info=True)
                st.warning("âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯. Ø³ÙŠØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Checksum.")

    return model_path.exists()

@st.cache_resource
def load_my_model(model_path: Path, gdrive_file_id: str, expected_checksum: str = None) -> keras.Model | None:
    """
    Loads the Keras model for image forgery detection.

    Args:
        model_path: The local path (Path object) to the Keras model file.
        gdrive_file_id: The Google Drive file ID for downloading the model.
        expected_checksum: The expected SHA256 checksum for the model file (optional).

    Returns:
        The loaded Keras model if successful, otherwise None.
    """
    if not TF_AVAILABLE:
        st.error("âŒ TensorFlow ØºÙŠØ± Ù…Ø«Ø¨Øª. ÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØª TensorFlow Ø£ÙˆÙ„Ø§Ù‹.")
        st.code("""
# Ù„Ø£Ø¬Ù‡Ø²Ø© Mac Ù…Ø¹ Ø´Ø±ÙŠØ­Ø© Apple Silicon (M1/M2/M3):
pip install tensorflow-macos tensorflow-metal

# Ù„Ø£Ø¬Ù‡Ø²Ø© Ø£Ø®Ø±Ù‰ (Windows/Linux/Mac Intel):
pip install tensorflow
        """)
        return None
    
    if not download_model_if_needed(model_path, gdrive_file_id, expected_checksum):
        return None 
    
    model_loading_message = st.empty()
    try:
        model_loading_message.info("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
        model = keras.models.load_model(
            str(model_path), # Keras expects string path
            compile=False # Skip compiling optimizer/loss for inference
        )
        model_loading_message.success("âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­!")
        model_loading_message.empty()
        return model
    except Exception as e:
        logger.error(f"Error loading Keras model from {model_path}: {e}", exc_info=True)
        model_loading_message.error("âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.")
        return None

# ------------------  PRE-PROCESSING HELPERS  ------------------

def generate_ela_image(pil_img: Image.Image, quality: int = ELA_QUALITY, scale_factor: float = ELA_SCALE_FACTOR) -> Image.Image:
    """
    Generates an Error Level Analysis (ELA) image from a PIL image.

    Args:
        pil_img: The original PIL Image object (should be in RGB mode).
        quality: The JPEG quality (0-100) for re-compression.
        scale_factor: Factor to enhance brightness of the difference image.

    Returns:
        A PIL Image object representing the ELA image.
    """
    # Ensure image is RGB
    if pil_img.mode != "RGB":
        pil_img = pil_img.convert("RGB")
    # Save to buffer as JPEG
    temp_buffer = io.BytesIO()
    pil_img.save(temp_buffer, 'JPEG', quality=quality)
    temp_buffer.seek(0)
    try:
        resaved = Image.open(temp_buffer)
    except UnidentifiedImageError as e:
        logger.error(f"Pillow UnidentifiedImageError during ELA resave: {e}", exc_info=True)
        st.error("Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù€ ELA. Ù‚Ø¯ ØªÙƒÙˆÙ† Ø§Ù„ØµÙˆØ±Ø© ØªØ§Ù„ÙØ©.")
        return Image.new("RGB", pil_img.size, (0,0,0))
    ela = ImageChops.difference(pil_img, resaved)
    ela = ImageEnhance.Brightness(ela).enhance(scale_factor)
    temp_buffer.close()
    return ela

def preprocess_image_rgb(pil_img: Image.Image, target_size_pil: tuple = IMAGE_SIZE_PIL) -> np.ndarray:
    """
    Preprocesses an RGB PIL Image for model input.

    Args:
        pil_img: The input PIL Image object.
        target_size_pil: A tuple (width, height) for resizing using PIL.

    Returns:
        A NumPy array representing the preprocessed image. Shape: (1, height, width, 3).
    """
    # Ensure image is RGB
    if pil_img.mode != "RGB":
        pil_img = pil_img.convert("RGB")
    pil_img = pil_img.resize(target_size_pil)
    arr = keras.preprocessing.image.img_to_array(pil_img)
    arr = tf.keras.applications.resnet_v2.preprocess_input(arr)
    return np.expand_dims(arr, 0)

def preprocess_image_ela(ela_pil: Image.Image, target_size_pil: tuple = IMAGE_SIZE_PIL) -> np.ndarray:
    """
    Preprocesses an ELA (Error Level Analysis) PIL Image for model input.

    Args:
        ela_pil: The input ELA PIL Image object.
        target_size_pil: A tuple (width, height) for resizing using PIL.

    Returns:
        A NumPy array representing the preprocessed ELA image. Shape: (1, height, width, 3).
    """
    if ela_pil.mode != "RGB":
        ela_pil = ela_pil.convert("RGB")
    ela_pil = ela_pil.resize(target_size_pil)
    arr = keras.preprocessing.image.img_to_array(ela_pil)  # values 0-255
    return np.expand_dims(arr, 0)

# Removed deprecated tf.function with experimental_relax_shapes
# Using standard tf.function without deprecated parameters
if TF_AVAILABLE:
    @tf.function
    def _tf_function_predict(model: keras.Model, rgb_input: tf.Tensor, ela_input: tf.Tensor) -> tf.Tensor:
        """Helper function to run model prediction within tf.function."""
        return model([rgb_input, ela_input], training=False)

def verify_image(pil_rgb: Image.Image, model: keras.Model) -> tuple[float, Image.Image | None]:
    """
    Verifies an image for tampering using the loaded dual-input model.

    Args:
        pil_rgb: The original PIL Image object (RGB) to verify.
        model: The loaded Keras model for prediction.

    Returns:
        A tuple containing:
            - proba (float): The raw probability score from the model.
            - ela_pil (Image.Image | None): The generated ELA PIL image, or None if ELA fails.
    """
    ela_pil = generate_ela_image(pil_rgb, quality=ELA_QUALITY, scale_factor=ELA_SCALE_FACTOR)
    if ela_pil is None or isinstance(ela_pil, tuple): # Defensive check if generate_ela_image changes error handling
        logger.error("ELA image generation failed.")
        return 0.0, None # Or handle error appropriately

    rgb_arr = preprocess_image_rgb(pil_rgb, target_size_pil=IMAGE_SIZE_PIL)
    ela_arr = preprocess_image_ela(ela_pil, target_size_pil=IMAGE_SIZE_PIL)
    
    if TF_AVAILABLE:
        # Use model.predict() which is the recommended approach for inference
        proba = model.predict([rgb_arr, ela_arr], verbose=0)[0,0]
    else: # Fallback if TF somehow became unavailable after initial check (should not happen)
        logger.error("TensorFlow became unavailable during verify_image.")
        st.error("Ø®Ø·Ø£ Ø­Ø±Ø¬ ÙÙŠ TensorFlow.")
        return 0.0, ela_pil # Return default/error state

    return float(proba), ela_pil

@st.cache_resource
def initialize_app() -> keras.Model | None:
    """
    Initializes the application by loading the forgery detection model.

    Returns:
        The loaded Keras model if successful, otherwise None.
    """
    if TF_AVAILABLE:
        # Show bypass warning if checksum is bypassed
        if BYPASS_CHECKSUM:
            st.info("â„¹ï¸ ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Checksum Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¤Ù‚ØªØ§Ù‹ Ù„Ù„ØªØ·ÙˆÙŠØ±.", icon="â„¹ï¸")

        # Pass None for checksum if bypassed
        checksum_to_use = None if BYPASS_CHECKSUM else MODEL_CHECKSUM
        model = load_my_model(MODEL_PATH, GDRIVE_FILE_ID, checksum_to_use)
        if model is None:
            st.error("âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.")
            return None
        return model
    else:
        st.error("âŒ TensorFlow ØºÙŠØ± Ù…Ø«Ø¨Øª. Ù„Ø§ ÙŠÙ…ÙƒÙ† ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø¯ÙˆÙ† TensorFlow.")
        st.warning("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ ØªØ«Ø¨ÙŠØª TensorFlow Ø¨Ø§Ù„Ø£Ù…Ø± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù†Ø¸Ø§Ù…Ùƒ:")
        st.code("""
# Ù„Ø£Ø¬Ù‡Ø²Ø© Mac Ù…Ø¹ Ø´Ø±ÙŠØ­Ø© Apple Silicon (M1/M2/M3):
pip install tensorflow-macos tensorflow-metal

# Ù„Ø£Ø¬Ù‡Ø²Ø© Ø£Ø®Ø±Ù‰ (Windows/Linux/Mac Intel):
pip install tensorflow
        """)
        return None

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„ØªØ·Ø¨ÙŠÙ‚ Streamlit ---
def main():
    """
    Main function to run the Streamlit application for image forgery detection.
    """
    # --- Sidebar Content ---
    with st.sidebar:
        st.image("https://img.icons8.com/external-flaticons-lineal-color-flat-icons/64/000000/external-detective-literature-flaticons-lineal-color-flat-icons.png", width=70) 

        st.markdown('<h2 style="text-align:center; margin-bottom:1rem;">Ø¹Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚</h2>', unsafe_allow_html=True)
        st.markdown("""
        <div class="sidebar-content">
        ÙŠÙ‡Ø¯Ù Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ Ø¥Ù„Ù‰ ÙƒØ´Ù Ø§Ù„ØªÙ„Ø§Ø¹Ø¨ ÙÙŠ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚. ÙŠØªÙ… ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ ØµÙˆØ±Ø© Ø¹Ø¨Ø± Ù…Ø³Ø§Ø±ÙŠÙ†: Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø£ØµÙ„ÙŠØ© (RGB) ÙˆØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø®Ø·Ø£ (ELA)ØŒ Ù„Ù„ÙƒØ´Ù Ø¹Ù† Ø£Ø¯Ù‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª.
        <br><br>
        Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ø§Ù„ÙŠ ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø±Ø£Ø³Ù‡ Ø§Ù„Ù…Ø®ØµØµ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª CASIA v2.0ØŒ Ù…Ø¹ Ø§Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Ø´Ø¨ÙƒØªÙŠ ResNet50V2 (Ù…Ø¯Ø±Ø¨Ø© Ù…Ø³Ø¨Ù‚Ù‹Ø§ Ø¹Ù„Ù‰ ImageNet) ÙƒÙ‚Ø§Ø¹Ø¯Ø© Ù…Ø¬Ù…Ø¯Ø© Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ù…ÙŠØ²Ø§Øª.
        </div>
        """, unsafe_allow_html=True)

        st.markdown('<h3 style="text-align:center; margin-top:2rem; margin-bottom:1rem;">ÙƒÙŠÙÙŠØ© Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…</h3>', unsafe_allow_html=True)
        st.markdown("""
        <div class="sidebar-content">
        <ol>
            <li>Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù…Ù† Ø¬Ù‡Ø§Ø²Ùƒ (JPG, PNG, TIFF, BMP).</li>
            <li>Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± "ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¢Ù†!".</li>
            <li>Ø§Ù†ØªØ¸Ø± Ø¸Ù‡ÙˆØ± Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙˆØªØ­Ù„ÙŠÙ„ ELA.</li>
        </ol>
        </div>
        """, unsafe_allow_html=True)

        st.markdown('<h3 style="text-align:center; margin-top:2rem; margin-bottom:1rem;">Ø§Ù„ØªÙƒÙ†ÙˆÙ„ÙˆØ¬ÙŠØ§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©</h3>', unsafe_allow_html=True)
        st.markdown("""
        <div class="sidebar-content">
        <ul>
            <li><b>Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:</b> Ø´Ø¨ÙƒØ© CNN Ø¨Ø¥Ø¯Ø®Ø§Ù„ Ù…Ø²Ø¯ÙˆØ¬ (ResNet50V2 x2).</li>
            <li><b>Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:</b> ResNet50V2 (ImageNetØŒ Ù…Ø¬Ù…Ø¯Ø©).</li>
            <li><b>Ø±Ø£Ø³ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:</b> Ø·Ø¨Ù‚Ø§Øª ØªØµÙ†ÙŠÙ Ù…ÙØ¯Ø±Ø¨Ø© Ø®ØµÙŠØµÙ‹Ø§.</li>
            <li><b>Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª:</b> RGB Ùˆ ELA.</li>
            <li><b>Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ù„Ù„Ø±Ø£Ø³):</b> CASIA v2.0.</li>
            <li><b>Ø§Ù„Ø£Ø¯ÙˆØ§Øª:</b> TensorFlow, Keras, Streamlit, Pillow, gdown.</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)
        st.markdown("---")
        st.markdown('<div class="sidebar-content" style="text-align:center;">', unsafe_allow_html=True)
        st.markdown('<h4 style="margin-bottom:0.3rem;">Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ø§Ù„Ø¨Ø©</h4>', unsafe_allow_html=True) 
        st.markdown('**Ù…Ø±ÙŠÙ… Ø¹Ø¨Ø¯ Ø§Ù„Ø¹Ø§Ù„ | Mariam Abd Alaal**', unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

        st.markdown("---")
        current_time = datetime.now()
        st.markdown(f'<p style="text-align: center; font-size: 0.85em; color:#666;">ğŸ“… {current_time.strftime("%Y-%m-%d %H:%M")}</p>', unsafe_allow_html=True)

        # Decision threshold slider - value will be used by main logic
        decision_threshold_from_slider = st.slider(
            "Ø¹ØªØ¨Ø© Ø§Ù„Ù‚Ø±Ø§Ø± (ØªØ¹ØªØ¨Ø± Ø§Ù„ØµÙˆØ±Ø© Ù…Ø²ÙˆØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªÙŠØ¬Ø© â‰¥ Ø§Ù„Ø¹ØªØ¨Ø©)",
            min_value=0.05, max_value=0.95, value=0.45, step=0.01,
            key="threshold_slider"
        )
    # --- End of Sidebar Content ---

    model = initialize_app()

    st.markdown('<div class="rtl-main-area">', unsafe_allow_html=True) 

    st.markdown('<h1 class="app-header">ğŸ” ÙƒØ§Ø´Ù ØªØ²ÙˆÙŠØ± Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ©</h1>', unsafe_allow_html=True)
    st.markdown('<p class="app-subheader">Ø§ÙƒØªØ´Ù Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØµÙˆØ±Ùƒ Ø£ØµÙ„ÙŠØ© Ø£Ù… ØªÙ… Ø§Ù„ØªÙ„Ø§Ø¹Ø¨ Ø¨Ù‡Ø§ Ø¨Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©</p>', unsafe_allow_html=True)

    if model is not None:
        st.markdown('<div class="upload-box">', unsafe_allow_html=True)
        st.markdown('<h2 class="section-header" style="margin-top:0; border-bottom:none; margin-bottom:1.5rem;">Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„</h2>', unsafe_allow_html=True)
        
        _col_fu_left, col_fu_mid, _col_fu_right = st.columns([1,2,1])
        with col_fu_mid:
            uploaded_file = st.file_uploader(
                " ", 
                type=["jpg", "jpeg", "png", "bmp", "tif", "tiff"], 
                label_visibility="collapsed", 
                key="main_file_uploader"
            )
        st.markdown('</div>', unsafe_allow_html=True)

        if uploaded_file is not None:
            # File size check
            if uploaded_file.size > MAX_FILE_SIZE_MB * 1024 * 1024:
                st.error(f"âŒ Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù ÙŠØªØ¬Ø§ÙˆØ² Ø§Ù„Ø­Ø¯ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡ ({MAX_FILE_SIZE_MB} Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª).")
                logger.warning(f"User uploaded file larger than limit: {uploaded_file.name}, size: {uploaded_file.size}")
                img_rgb_pil = None
            else:
                try:
                    img_rgb_pil = Image.open(uploaded_file)
                    # Image dimension check
                    if img_rgb_pil.width > MAX_IMAGE_DIMENSION or img_rgb_pil.height > MAX_IMAGE_DIMENSION:
                        st.error(f"âŒ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø© ÙƒØ¨ÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ (Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ {MAX_IMAGE_DIMENSION}x{MAX_IMAGE_DIMENSION} Ø¨ÙƒØ³Ù„).")
                        logger.warning(f"User uploaded image with excessive dimensions: {uploaded_file.name}, {img_rgb_pil.size}")
                        img_rgb_pil = None
                    elif img_rgb_pil.mode != "RGB": # Ensure it's RGB after opening
                         img_rgb_pil = img_rgb_pil.convert("RGB")

                except UnidentifiedImageError:
                    st.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù…Ù„Ù Ø§Ù„ØµÙˆØ±Ø©. ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØ±Ø© ØµØ§Ù„Ø­.")
                    logger.warning(f"User uploaded an unidentifiable image file: {uploaded_file.name}", exc_info=True)
                    img_rgb_pil = None
                except Exception as e:
                    st.error("âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø¨ØµÙˆØ±Ø© Ø£Ø®Ø±Ù‰.")
                    logger.error(f"Error loading uploaded image {uploaded_file.name}: {e}", exc_info=True)
                    img_rgb_pil = None

            if img_rgb_pil:
                col_rgb, col_ela = st.columns(2, gap="large")

                with col_rgb:
                    st.markdown("#### Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©")
                    st.image(img_rgb_pil, use_container_width=True, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©")

                with col_ela:
                    st.markdown("#### ØµÙˆØ±Ø© ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·Ø£ (ELA)")
                    ela_slot = st.empty()
                    ela_slot.info("Ø§Ø¶ØºØ· Ø²Ø± Ø§Ù„ØªØ­Ù‚Ù‚ Ù„Ø¥Ø¸Ù‡Ø§Ø± ØµÙˆØ±Ø© ELA.")

                check_btn_center = st.columns([1,1,1])[1]
                with check_btn_center:
                    if st.button("ğŸ”¬ ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¢Ù†!", key="verify_button", use_container_width=True):
                        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):
                            proba, ela_pil_result = verify_image(img_rgb_pil, model)

                        if ela_pil_result:
                            with col_ela: # Update ELA image display
                                ela_slot.image(ela_pil_result, use_container_width=True, caption="ØµÙˆØ±Ø© ELA Ø§Ù„Ù†Ø§ØªØ¬Ø©")
                        else:
                            with col_ela:
                                ela_slot.error("Ù„Ù… ÙŠØªÙ…ÙƒÙ† Ù…Ù† Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© ELA.")

                        st.markdown("---")
                        st.markdown('<h2 class="section-header">ğŸ“œ Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„</h2>', unsafe_allow_html=True)
                        
                        # Use threshold from sidebar slider
                        if proba >= decision_threshold_from_slider:
                            conf = proba * 100
                            st.markdown('<div class="result-box forged"><h3>âš ï¸ Ø§Ù„ØµÙˆØ±Ø© ØªØ¨Ø¯Ùˆ Ù…Ø²ÙˆØ±Ø©</h3></div>', unsafe_allow_html=True)
                            st.metric("Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© (Ù…Ø²ÙˆØ±Ø©)", f"{conf:.2f}%")
                        else:
                            conf = (1 - proba) * 100
                            st.markdown('<div class="result-box authentic"><h3>âœ… Ø§Ù„ØµÙˆØ±Ø© ØªØ¨Ø¯Ùˆ Ø£ØµÙ„ÙŠØ©</h3></div>', unsafe_allow_html=True)
                            st.metric("Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© (Ø£ØµÙ„ÙŠØ©)", f"{conf:.2f}%")

                        with st.expander("ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©"):
                            st.write(f"Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: **{proba:.6f}**")
                            st.write(f"Ø¹ØªØ¨Ø© Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©: **{decision_threshold_from_slider:.2f}**")
                            st.caption("Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ© â‰¥ Ø¹ØªØ¨Ø© Ø§Ù„Ù‚Ø±Ø§Ø±ØŒ ØªØ¹ØªØ¨Ø± Ø§Ù„ØµÙˆØ±Ø© Ù…Ø²ÙˆØ±Ø©.")
            
            elif uploaded_file and not img_rgb_pil: # Error occurred during file processing
                 pass # Error messages handled above
        
        else: # No file uploaded
            st.markdown("""
            <div style="text-align: center; padding: 2rem; background-color: #e9ecef; border-radius: 10px; margin: 2rem auto; max-width: 700px; box-shadow: 0 4px 15px rgba(0,0,0,0.05);">
                <img src="https://img.icons8.com/fluency/96/000000/image-file.png" alt="Upload icon" width="70" style="margin-bottom: 1rem;">
                <p style="font-size: 1.3rem; margin-bottom: 0.5rem;">Ù„Ù… ÙŠØªÙ… Ø±ÙØ¹ Ø£ÙŠ ØµÙˆØ±Ø© Ø¨Ø¹Ø¯.</p>
                <p style="font-size: 1rem; color: #495057;">ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ø£Ø¹Ù„Ø§Ù‡ Ù„Ø§Ø®ØªÙŠØ§Ø± ØµÙˆØ±Ø© ÙˆØ§Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ù‚Ù‚.</p>
            </div>
            """, unsafe_allow_html=True)
    else: 
        st.error("âŒ Ø®Ø·Ø£ ÙØ§Ø¯Ø­: Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ. Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù…ØªØ§Ø¨Ø¹Ø© Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ­Ù‚Ù‚.")
        st.info("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§ØªØµØ§Ù„Ùƒ Ø¨Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ù„ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ù…Ø±Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ØŒ Ø£Ùˆ ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ù„ÙŠ ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª TensorFlow.")
        logger.critical("Application cannot run because the model failed to initialize.")

    st.markdown('</div>', unsafe_allow_html=True) # End of rtl-main-area

if __name__ == "__main__":
    # Note on TensorFlow optimization:
    # Ensure TensorFlow is installed with optimizations for your CPU (e.g., oneDNN for Intel)
    # or with GPU support if available. This can significantly impact model inference speed.
    # For advanced users: Model quantization (e.g., to INT8) can further speed up inference
    # at the cost of a small potential accuracy drop.
    main()